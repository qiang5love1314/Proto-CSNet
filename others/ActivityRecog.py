"ideaï¼šcombine BLS with Transformer to recognize activities"
# æ•°æ®é›†ï¼šD:\pycharm\files\OurActivityDataset\OurActivityDataset\Processed Data\bedroom(\meetingroom)
import numpy as np
from scipy.io import loadmat, savemat
import os
os.environ['CUDA_VISIBLE_DEVICES']='1'
import transformer_encoder
from Comparison import CSImodel
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.decomposition import KernelPCA
from tqdm import tqdm
import MyNewModel
import argparse
import torch
import time
from scipy import signal
import matplotlib.pyplot as plt
from scipy import signal
import pywt
import torch.utils.data as Data
from torch import nn
import transformers
from transformers import (AutoConfig,
    AutoTokenizer,
    FlaxAutoModelForSequenceClassification,
    AutoModelForSequenceClassification,
    HfArgumentParser,
    PretrainedConfig,
    TrainingArguments,
    is_tensorboard_available,)
from transformers.utils import check_min_version, get_full_repo_name
from transformers import Trainer, TrainingArguments
from datasets import Dataset

# æ®‹å·®ç½‘ç»œ
class RN(nn.Module):
    def __init__(self):
        super(RN, self).__init__()
        # çº¿æ€§å±‚ï¼Œå¯¹è¾“å…¥è¿›è¡Œä¸€ç³»åˆ—çº¿æ€§å˜æ¢å’Œæ¿€æ´»æ“ä½œï¼Œä»è€Œæå–è¾“å…¥æ•°æ®çš„ç‰¹å¾è¡¨ç¤º
        self.linear_stack = nn.Sequential(
            nn.Linear(90, 128),
            nn.Hardsigmoid(),
            nn.Linear(128, 90),
            nn.Hardsigmoid(),
        )
        # çº¿æ€§å±‚ï¼Œå¯¹æ•°æ®è¿›ä¸€æ­¥ç‰¹å¾æå–
        self.linear_stack_2 = nn.Sequential(
            nn.Linear(90, 64),
            # ç¡¬sigmoidåŠ é€Ÿè®¡ç®—
            nn.Hardsigmoid(),
            nn.Linear(64, 32),
            nn.Hardsigmoid(),
        )
        # è¾“å‡ºå±‚
        self.output_layer = nn.Linear(32, 1)
        # æŸå¤±å‡½æ•°
        self.loss_f = nn.CrossEntropyLoss()

    # å‰å‘ä¼ æ’­ï¼Œåœ¨trainæ—¶è¾“å‡ºlosså’Œé¢„æµ‹å€¼
    def forward(self, x, labels, mode='train'):
        y = self.linear_stack(x)
        # æ®‹å·®
        y = y + x
        y = self.linear_stack_2(y)
        y = self.output_layer(y)

        if mode is 'train':
            return {
                'loss': self.loss_f(y, labels),
                'predictions': y
            }
        return y

# è®¡ç®—é¢„æµ‹ç»“æœçš„å‡†ç¡®ç‡
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    acc = (labels == preds).sum()/len(labels)
    return {
        'accuracy': acc,
    }

# åˆå¹¶æ•°æ®é›†
def merge_csi_DataAndLabel(path):

    listDir = []
    csiData = []
    activity = []
    labelList = ['lying', 'sitting', 'running', 'walking', 'pick up', 'wave hand', 'jump', 'squat', 'site down', 'stand up', 'fall down']

    # è·å–æ•°æ®é›†å­æ–‡ä»¶å¤¹åˆ—è¡¨
    for root, dirs, files in os.walk(path, topdown=False):
        listDir = dirs
    listDir = sorted(list(map(int, listDir)))

    # è·å–åŸå§‹CSIæ•°æ®
    for i in range(len(listDir)):
        subpath = path + str(listDir[i])
        whole_file = [os.path.join(subpath, file) for file in os.listdir(subpath)]
        # å¯¹äºæ¯ä¸€ä¸ªè·¯å¾„ï¼Œå°†å…¶æ‰“å¼€ä¹‹åï¼Œä½¿ç”¨readlinesè·å–å…¨éƒ¨å†…å®¹
        for w in whole_file:
            data = loadmat(w)['csi']
            csiData.append(data)
    csiData = np.array(csiData, dtype=complex)

    # æ„é€ æ ‡ç­¾
    labelNum = []
    for i in range(len(listDir)):
        if i != len(listDir)-1:
            activity.extend([labelList[i]] * 100)
            labelNum.extend([i] * 100)
        else:
            activity.extend([labelList[i]] * 50)
            labelNum.extend([i] * 50)
    labelNum = np.array(labelNum)

    return csiData, activity, labelNum

def data_loader(data):
    loader = Data.DataLoader(
        dataset=data,
        batch_size=200,
        shuffle=True,
        num_workers=1,
    )
    return loader

def get_args():
    parser = argparse.ArgumentParser(description='Transformer-BLS')
    parser.add_argument('--sample', type=int, default=1, help='sample length on temporal side')
    parser.add_argument('--batch', type=int, default=16, help='batch size [default: 16]')
    parser.add_argument('--lr', type=float, default=0.001, help='learning rate [default: 0.001]')
    parser.add_argument('--epoch', type=int, default=50, help='number of epoch [default: 20]')
    parser.add_argument('--hlayers', type=int, default=6, help='horizontal transformer layers [default: 6]')
    parser.add_argument('--hheads', type=int, default=9, help='horizontal transformer head [default: 9]')
    parser.add_argument('--vlayers', type=int, default=1, help='vertical transformer layers [default: 1]')
    parser.add_argument('--vheads', type=int, default=200, help='vertical transformer head [default: 200]')
    parser.add_argument('--com_dim', type=int, default=50, help='compressor vertical transformer layers [default: 50]')
    args = parser.parse_args()
    return args

if __name__ == "__main__":
    path1 = r'./Processed Data/bedroom/'
    path2 = r'./Processed Data/meetingroom/'
    csiData, csiLabel, labelNum = merge_csi_DataAndLabel(path1)   # every activity has 100 samples except fall down which only includes 50 samples.
    "csiData [1050, [3, 30, 200]], csiLabel [1050, 1]"
    amplitudeCSI = abs(csiData)

    # å¤æ•°å½¢å¼ä¸‹CSIçš„å…ˆå¿«é€Ÿå‚…é‡Œå¶å˜åŒ–å¤„ç†æ•ˆæœæ›´å¥½ï¼Œç„¶åå†å°æ³¢å˜æ¢
    # fftData = np.fft.fft(csiData)
    fftData = np.fft.fft(amplitudeCSI)
    # b, a = signal.butter(5, 3 * 2 / 50, 'lowpass')    #è¿‡äºå¹³æ»‘ï¼Œæ•°æ®ç‰¹å¾æ¶ˆå¤±
    # csiData = signal.filtfilt(b, a, csiData)
    wavename = 'db5'
    ca, cd = pywt.dwt(fftData, wavename)
    dwtCSI = pywt.idwt(None, cd, wavename, 'smooth')

    # AntennA, AntennB, AntennC = dwtCSI[0][0], dwtCSI[0][1], dwtCSI[0][2]
    # for i in range(30):
    #     plt.plot(AntennA[i])
    #     plt.plot(AntennB[i])
    #     plt.plot(AntennC[i])
    # plt.show()

    # é¢‘è°±å›¾ç»˜åˆ¶ï¼Œä½†æ„Ÿè§‰æœ‰ç‚¹é—®é¢˜
    # f, t, zxx = signal.stft(amplitudeCSI[100][2][25])
    # plt.pcolormesh(t, f, np.abs(zxx))
    # plt.colorbar()
    # plt.show()

    csi = torch.from_numpy(dwtCSI).float().unsqueeze(0)  # 1050*3*30*200
    # csiå¼ é‡ä¸å‚ä¸åå‘ä¼ æ’­
    csi.requires_grad = False
    # å¾—åˆ°ä¸€ä¸ª1050*200*90çš„å¼ é‡
    csi = csi.view(1050, 200, 90)
    # åœ¨ç¬¬0ç»´åº¦ä¸Šæ‹¼æ¥ï¼Œå¾—åˆ°ä¸€ä¸ª1050*200*90*1çš„å¼ é‡
    csi = torch.cat([csi], dim=0)

    # å¾—åˆ°ä¸€ä¸ª1050*200*90çš„å¼ é‡
    # csi = torch.cat(list(csi), dim=0)
    # labelNum = torch.from_numpy(labelNum).int()
    # print(labelNum)

    # x_train, y_train, x_valid, y_valid = train_test_split(csi, labelNum, test_size=0.2, random_state=20)

    # å°†csiå˜æˆtorchå¼ é‡
    labelNum = torch.tensor(labelNum)
    labelNum = torch.unsqueeze(labelNum, 1)
    # æ„é€ æ•°æ®é›†ï¼Œå°†æ•°æ®å’Œæ ‡ç­¾æ‹¼æ¥èµ·æ¥
    MIXdata = Data.TensorDataset(csi, labelNum)
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_dataset, test_dataset = torch.utils.data.random_split(MIXdata, [840, 210], random_state=40, shuffle=True)
    # è·å–æ•°æ®
    train_data = data_loader(train_dataset)
    trainDataset = Dataset.from_dict({'x':csi, 'labels':labelNum})
    test_dataset = data_loader(test_dataset)
    testDataset = Dataset.from_dict({'x': csi, 'labels': labelNum})

    args = get_args()

    # åˆ›å»ºTransformerMæ¨¡å‹å®ä¾‹
    model = MyNewModel.TransformerM(args)

    if torch.cuda.is_available():
        model = model.cuda()
    criterion = torch.nn.NLLLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    device = torch.device("cuda: 0" if torch.cuda.is_available() else "cpu")
    n_epochs = args.epoch
    best = 0.0

    for epoch in range(n_epochs):
        running_loss = 0.0
        running_correct = 0
        tr_acc = 0.
        total_num = 0
        print("\nEpoch{}/{}".format(epoch, n_epochs))
        print("-" * 10)
        #print("\n")
        steps = len(train_data)
        model.train()
        time_start = time.time()
        # è®­ç»ƒé›†
        for batch in tqdm(train_data):
            X_train, Y_train = batch
            Y_train = Y_train.unsqueeze(dim=1)
            Y_train = Y_train.long()
            X_train, Y_train = X_train.to(device), Y_train.to(device)

            outputs = model(X_train)
            pred = torch.max(outputs, 1)[1]
            # å˜ä¸º1ç»´
            Y_train=Y_train.view(-1)
            loss = criterion(outputs, Y_train)
            # åŸæœ‰å†™æ³•ï¼š
            # loss = criterion(outputs, Y_train[batch])
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            running_loss += loss.item()
            running_correct = (pred.cpu() == Y_train.cpu()).sum()
            tr_acc += running_correct.item()
            total_num += len(batch[0])

        time_end = time.time()
        print('time cost', time_end - time_start, 's')
        running_loss = 0.0
        running_correct = 0
        tr_acc = 0.
        total_num = 0
        print("\nStart validation")
        print("-" * 10)
        #print("\n")
        steps = len(train_data)
        model.eval()
        # conf_matrix = [[0 for _ in range(len(aclist))] for _ in range(len(aclist))]

        # æµ‹è¯•é›†
        time_start = time.time()
        for batch in tqdm(test_data):
            X_train, Y_train = batch
            # Y_train = Y_train.unsqueeze(dim=1)
            Y_train = Y_train.long()
            X_train, Y_train = X_train.to(device), Y_train.to(device)
            outputs = model(X_train)
            pred = torch.max(outputs, 1)[1]
            running_correct = (pred.cpu() == Y_train.cpu()).sum()
            # conf_matrix = gen_conf_matrix(pred, Y_train, conf_matrix)
            tr_acc += running_correct.item()
            total_num += len(batch[0])
            # running_correct += torch.sum(pred == Y_train.data)
            acc = tr_acc/total_num
        time_end = time.time()
        print('time cost', time_end - time_start, 's')
        print("\nAccuracy is", tr_acc/total_num)
        if best < acc:
            best = acc
            # write_to_file(conf_matrix)
            torch.save(model, 'model\\model.pkl')
        print("\nBest is", best)



    # # ç”Ÿæˆæ¨¡å‹å®ä¾‹
    #
    # # æ¨¡å‹å¯¹è±¡ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ä¸Šè¿›è¡Œè®¡ç®—ï¼Œä»¥æé«˜è®¡ç®—æ•ˆç‡å’Œå‡å°‘å†…å­˜å ç”¨ã€‚
    # model = RN().to(device=device)
    # # model = model
    # training_args = TrainingArguments(
    #     output_dir='./results',           # output directory ç»“æœè¾“å‡ºåœ°å€
    #     num_train_epochs=100,             # total # of training epochs è®­ç»ƒæ€»æ‰¹æ¬¡
    #     per_device_train_batch_size=100,  # batch size per device during training è®­ç»ƒæ‰¹å¤§å°
    #     per_device_eval_batch_size=10,    # batch size for evaluation è¯„ä¼°æ‰¹å¤§å°
    #     logging_dir='./logs/rn_log',    # directory for storing logs æ—¥å¿—å­˜å‚¨ä½ç½®
    #     learning_rate=1e-3,               # å­¦ä¹ ç‡
    #     save_steps=False,
    # )
    #
    # trainer = Trainer(
    #     model=model,                      # the instantiated ğŸ¤— Transformers model to be trained éœ€è¦è®­ç»ƒçš„æ¨¡å‹
    #     args=training_args,               # training arguments, defined above è®­ç»ƒå‚æ•°
    #     train_dataset=trainDataset,            # training dataset è®­ç»ƒé›†
    #     eval_dataset=testDataset,         # evaluation dataset æµ‹è¯•é›†
    #     compute_metrics=compute_metrics   # è®¡ç®—æŒ‡æ ‡æ–¹æ³•
    # )
    #
    # # trainer.train()
    # evaluate = trainer.evaluate()
    # print(evaluate.values())